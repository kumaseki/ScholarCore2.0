import time
import logging
from openai import OpenAI, APIError, RateLimitError, APITimeoutError
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from src.core.config import GlobalConfig
from src.core.exceptions import LLMError, LLMParseError, ConfigurationError
from src.utils.text_utils import clean_and_parse_json

logger = logging.getLogger("driver.llm")

class DeepSeekDriver:
    def __init__(self):
        self.config = GlobalConfig
        api_key = self.config.get('llm.api_key')
        base_url = self.config.get('llm.base_url')
        
        if not api_key:
            raise ConfigurationError("DeepSeek API Key not found in .env")

        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = self.config.get('llm.model', 'deepseek-chat')
        # é»˜è®¤å‚æ•°
        self.default_temp = self.config.get('llm.temperature', 0.3)
        self.max_tokens = self.config.get('llm.max_tokens', 8000)

    def _log_usage(self, response):
        """è®°å½• Token æ¶ˆè€—ï¼Œå“ªæ€•æ˜¯ç²—ç•¥çš„"""
        try:
            usage = response.usage
            logger.info(f"LLM Usage: In={usage.prompt_tokens}, Out={usage.completion_tokens}, Total={usage.total_tokens}")
        except AttributeError:
            logger.warning("LLM response missing usage stats.")

    # ä½¿ç”¨ Tenacity åº“è¿›è¡Œé‡è¯• (æ¯”æ‰‹å†™è£…é¥°å™¨æ›´ç¨³å¥)
    # é‡è¯•æ¡ä»¶ï¼šAPIé”™è¯¯ã€é™æµã€è¶…æ—¶
    # ç­–ç•¥ï¼šæœ€å¤šè¯• 3 æ¬¡ï¼ŒæŒ‡æ•°é€€é¿ (2s, 4s, 8s...)
    @retry(
        retry=retry_if_exception_type((APIError, RateLimitError, APITimeoutError)),
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        reraise=True
    )
    def _call_api(self, messages, json_mode=False):
        """åº•å±‚çš„ API è°ƒç”¨ï¼ŒåŒ…è£¹äº†é‡è¯•é€»è¾‘"""
        try:
            # âœ… æ–°å¢ï¼šåœ¨è¯·æ±‚å‘å‡ºå‰è®°å½•æ—¥å¿— (DEBUGçº§åˆ«ï¼Œä½†åœ¨è°ƒè¯•æ—¶å¾ˆæœ‰ç”¨)
            # å¦‚æœä½ è§‰å¾—å¤ªåµï¼Œå¯ä»¥æŠŠçº§åˆ«æ”¹æˆ DEBUGï¼Œä½†ç°åœ¨ä¸ºäº†è®©ä½ å®‰å¿ƒï¼Œæˆ‘ä»¬ç”¨ INFO
            logger.info(f"ğŸ¤– Requesting DeepSeek... (JSON Mode: {json_mode})")
            
            start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.default_temp,
                max_tokens=self.max_tokens,
                stream=False,
                response_format={"type": "json_object"} if json_mode else None
            )
            duration = time.time() - start_time
            logger.info(f"âœ… DeepSeek Responded in {duration:.2f}s")
            
            self._log_usage(response)
            return response.choices[0].message.content
        except Exception as e:
            # æ•è·æ‰€æœ‰ OpenAI æŠ›å‡ºçš„å¼‚å¸¸ï¼ŒåŒ…è£…æˆæˆ‘ä»¬è‡ªå·±çš„ LLMError
            # è¿™æ ·ä¸Šå±‚é€»è¾‘ä¸éœ€è¦ import openai å°±èƒ½å¤„ç†é”™è¯¯
            logger.error(f"DeepSeek API Error: {str(e)}")
            raise LLMError(f"DeepSeek connection failed: {str(e)}") from e

    def chat(self, system_prompt: str, user_content: str) -> str:
        """
        æ™®é€šå¯¹è¯æ¨¡å¼ã€‚
        è¿”å›ï¼šå­—ç¬¦ä¸²
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ]
        return self._call_api(messages, json_mode=False)

    def chat_json(self, system_prompt: str, user_content: str) -> dict:
        """
        JSON æ¨¡å¼ã€‚
        è¿”å›ï¼šå­—å…¸ (Dict)
        æ³¨æ„ï¼šè¿™é‡ŒåŒ…å«äº†ä¸¤å±‚é‡è¯•ï¼š
        1. _call_api è´Ÿè´£ç½‘ç»œå±‚é¢çš„é‡è¯•ã€‚
        2. è¿™é‡Œè´Ÿè´£è§£æå¤±è´¥çš„é‡è¯•ï¼ˆæ‰‹åŠ¨ç®€å•çš„é‡è¯•ä¸€æ¬¡ï¼Œæˆ–è€…ç›´æ¥æŠ›å‡ºè®©ä¸Šå±‚å†³å®šï¼‰ã€‚
        """
        # å¼ºåˆ¶åœ¨ prompt é‡ŒåŠ ä¸Š JSON æŒ‡ä»¤ï¼ŒåŒé‡ä¿é™©
        if "json" not in system_prompt.lower():
            system_prompt += "\n\nIMPORTANT: Output ONLY valid JSON."

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ]

        # å°è¯•è°ƒç”¨
        raw_content = self._call_api(messages, json_mode=True) # DeepSeek æ”¯æŒ native json mode

        # æ¸…æ´—ä¸è§£æ
        try:
            return clean_and_parse_json(raw_content)
        except LLMParseError as e:
            logger.warning(f"JSON parse failed, retrying once... Error: {e}")
            # ç®€å•çš„å†è¯•ä¸€æ¬¡ï¼Œæœ‰æ—¶å€™é‡è¯•å°±èƒ½è§£å†³ä¹±ç é—®é¢˜
            # ä¹Ÿå¯ä»¥åœ¨è¿™é‡ŒåŠ å…¥ 'Refinement Prompt' å‘Šè¯‰ AI æ ¼å¼é”™äº†ï¼Œä½†é‚£æ˜¯ Phase 3 çš„äº‹
            time.sleep(1)
            raw_content_retry = self._call_api(messages, json_mode=True)
            return clean_and_parse_json(raw_content_retry)